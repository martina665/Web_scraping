{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obiettivo= webscrap i siti di giornale come ansa/ corriere della sera etc...\n",
    "Per ora= skytg24 succesfully scraped\n",
    "\n",
    "Codice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con questo codice vengono:\n",
    "- richieste le librerie\n",
    "- indicato il link che si vuole scrape\n",
    "- creato un oggetto con Beautiful soup\n",
    "- in questo si riesce bene a prendere l'href, il titolo, e poi l'href viene utilizzato per prendere il contenuto dell'articolo che ci interessa,\n",
    "- funziona bene perchè è un'unica lista che viene trasformata poi in dizionario e alla fine in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#codice che viene = Skytg24:\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "response = requests.get('https://tg24.sky.it/mondo')\n",
    "soup = BeautifulSoup(response.text)\n",
    "\n",
    "data = []\n",
    "\n",
    "for a in soup.find_all('a', {'class': 'c-card'}):\n",
    "\n",
    "    response = requests.get(a.get('href'))\n",
    "    asoup = BeautifulSoup(response.text)\n",
    "    data.append({\n",
    "        'Title': a.h2.get_text(strip=True),\n",
    "        'content': asoup.article.get_text(strip=True),\n",
    "        'PageLink': a.get('href'),        \n",
    "        'category': 'mondo',\n",
    "        'Date':datetime.now(),\n",
    "\n",
    "    })\n",
    "\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problema = rifare la stessa cosa ad esempio con sito ansa(?)\n",
    "codice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request,sys,time\n",
    "import csv\n",
    "from csv import writer\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "#scrape the content(entire article ) of the news  with Beautifulsoup\n",
    "#source= open online = ucraina section\n",
    "\n",
    "r= requests.get('https://www.ansa.it/sito/notizie/politica/politica.shtml')\n",
    "b= soup(r.content, 'lxml')\n",
    "\n",
    "########################WQUESTO######################\n",
    "title=[]\n",
    "links=[]\n",
    "content=[]\n",
    "\n",
    "for c in b.findAll('h3',{'class':'news-title'}):\n",
    "   title.append(c.text.strip())  \n",
    "for c in b.findAll(\"h3\", {\"class\": \"news-title\"}):#metti la virgola così specifica più classi\n",
    "    links.append(c.a[\"href\"])\n",
    "for link in links: \n",
    "    page=requests.get('https://www.ansa.it'+link)\n",
    "    bsjop=soup(page.content)\n",
    "    for n in bsjop.findAll('div',{'itemprop': 'articleBody'}):\n",
    "        content.append(n.text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {'Title':title[:47], \n",
    "        'content':content[:47], \n",
    "        'PageLink':links[:47],\n",
    "        'category': 'politica', #########IMPORTANTE CAMBIA SEMPRE QUESTO\n",
    "        'Date':datetime.now()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obiettivo= ricreare il codice di skytg24 anche per la pagina ansa\n",
    "prblema del codice ansa= lavorando con più liste queste finiscono per avere diversa lunghezza e sono imprecise nel risultato, \n",
    "altro problema= l'href dell'ansa è incompleto (manca la prima parte con https e quindi con l'altro codice non riconosce il path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "altro obiettivo: https://www.corriere.it/ webcrape il corriere della sera perchè il sito è mooolto simile a skytg24 e da qui riuscire a scrape tutto il resto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "su youtube: https://www.youtube.com/watch?v=BYqpxHxl-nc questo è il metodono con tante liste da ottimizzare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('webscrap')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4cf5878a4ec1d680f9f76bd95571ab97a310cf97db5940d832842dd4c6bf3c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
